{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Automated Machine Learning with AutomML\n",
    "_**Classification with Local Compute**_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this lab, you will use your AdeventureWorks model training feature data you created earlier, to let AutoML find the best performing model.\n",
    "\n",
    "In this notebook you will learn how to:\n",
    "1. Create an `Experiment` in an existing `Workspace`.\n",
    "2. Configure AutoML using `AutoMLConfig`.\n",
    "3. Train the model using local compute.\n",
    "4. Explore the results.\n",
    "5. Test the best fitted model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "As part of the setup you have already created an Azure ML `Workspace` object. For AutoML you will need to create an `Experiment` object, which is a named object in a `Workspace` used to run experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.17\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "print(azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to your Azure Machine Learning service workspace.\n",
    "\n",
    "There are two ways to do this:\n",
    "\n",
    "- Using the workspace config file we created earlier.\n",
    "- Calling the workspace get() method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Using the workspace config file...\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.location, ws.resource_group, ws.location, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2: Using the get() method...\n",
    "\n",
    "from azureml.core import Workspace, Experiment, Run\n",
    "ws = Workspace.get(name='dp100labws',\n",
    "                   subscription_id='<your-subscription_id',\n",
    "                   resource_group='dp100labrg'\n",
    "                  )\n",
    "print(ws.name, ws.location, ws.resource_group, ws.location, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "print('Modules loaded...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Experiment Name</th>\n",
       "      <td>automl-local-classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Location</th>\n",
       "      <td>eastus2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Project Directory</th>\n",
       "      <td>./sample_projects/automl-local-classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Resource Group</th>\n",
       "      <td>rg_amlsstudentworkspace1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SDK version</th>\n",
       "      <td>1.0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subscription ID</th>\n",
       "      <td>050aedf0-1ce2-495f-a726-be8756f5ab18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Workspace Name</th>\n",
       "      <td>amlsstudentworkspace1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                \n",
       "Experiment Name    automl-local-classification                  \n",
       "Location           eastus2                                      \n",
       "Project Directory  ./sample_projects/automl-local-classification\n",
       "Resource Group     rg_amlsstudentworkspace1                     \n",
       "SDK version        1.0.17                                       \n",
       "Subscription ID    050aedf0-1ce2-495f-a726-be8756f5ab18         \n",
       "Workspace Name     amlsstudentworkspace1                        "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ws = Workspace.from_config()\n",
    "\n",
    "# Choose a name for the experiment and specify the project folder.\n",
    "experiment_name = 'dp100lab-automl'\n",
    "project_folder = './dp100lab'\n",
    "\n",
    "experiment = Experiment(ws, experiment_name)\n",
    "\n",
    "output = {}\n",
    "output['SDK version'] = azureml.core.VERSION\n",
    "output['Subscription ID'] = ws.subscription_id\n",
    "output['Workspace Name'] = ws.name\n",
    "output['Resource Group'] = ws.resource_group\n",
    "output['Location'] = ws.location\n",
    "output['Project Directory'] = project_folder\n",
    "output['Experiment Name'] = experiment.name\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "outputDf = pd.DataFrame(data = output, index = [''])\n",
    "outputDf.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to existing workspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore data\n",
    "### You already explored the data in the last lab. You need to copy the data into the cloud so it can be accessed by your cloud training environment. We saved the model training data to a csv file so all we have to do is load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iimport pandas as pd\n",
    "\n",
    "df_features = pd.read_csv(r'./BikeModelFeatures.csv')\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train , x_test = train_test_split(df_features.values,test_size=0.2)       #test_size=0.5(whole_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Touring-2000', 'Touring-1000', 'Road-550-W', ..., 'Road-650',\n",
       "       'Road-750', 'Mountain-100'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = x_train[:,3]\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Touring-2000', 'Road-750', 'Mountain-200', ..., 'Mountain-200',\n",
       "       'Mountain-400-W', 'Touring-2000'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = x_test[:,3]\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['S', 'M', 'GB'],\n",
       "       ['S', 'M', 'AU'],\n",
       "       ['M', 'F', 'DE'],\n",
       "       ...,\n",
       "       ['M', 'F', 'US'],\n",
       "       ['M', 'F', 'US'],\n",
       "       ['M', 'M', 'AU']], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train[:,0:3]\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['S', 'M', 'AU'],\n",
       "       ['M', 'M', 'US'],\n",
       "       ['M', 'M', 'GB'],\n",
       "       ...,\n",
       "       ['M', 'M', 'GB'],\n",
       "       ['S', 'F', 'FR'],\n",
       "       ['M', 'F', 'AU']], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = x_test[:,0:3]\n",
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3041"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "len(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "Instantiate an `AutoMLConfig` object to specify the settings and data used to run the experiment.\n",
    "\n",
    "|Property|Description|\n",
    "|-|-|\n",
    "|**task**|classification or regression|\n",
    "|**primary_metric**|This is the metric that you want to optimize. Regression supports the following primary metrics: <br><i>spearman_correlation</i><br><i>normalized_root_mean_squared_error</i><br><i>r2_score</i><br><i>normalized_mean_absolute_error</i>|\n",
    "|**iteration_timeout_minutes**|Time limit in minutes for each iteration.|\n",
    "|**iterations**|Number of iterations. In each iteration AutoML trains a specific pipeline with the data.|\n",
    "|**n_cross_validations**|Number of cross validation splits.|\n",
    "|**X**|(sparse) array-like, shape = [n_samples, n_features]|\n",
    "|**y**|(sparse) array-like, shape = [n_samples, ], targets values.|\n",
    "|**path**|Relative path to the project folder. AutoML stores configuration files for the experiment under this folder. You can specify a new empty folder.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_config = AutoMLConfig(task = 'classification',\n",
    "                             iteration_timeout_minutes = 10,\n",
    "                             iterations = 10,\n",
    "                             primary_metric = 'precision_score_weighted',\n",
    "                             n_cross_validations = 5,\n",
    "                             debug_log = 'automl.log',\n",
    "                             verbosity = logging.INFO,\n",
    "                             X = x_train, \n",
    "                             y = y_train,\n",
    "                             preprocess=True,\n",
    "                             path = project_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the `submit` method on the experiment object and pass the run configuration. Execution of local runs is synchronous. Depending on the data and the number of iterations this can run for a while.\n",
    "In this example, we specify `show_output = True` to print currently running iterations to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local machine\n",
      "Parent Run ID: AutoML_2e1a8864-811d-45cf-adf6-4a161a165ef6\n",
      "********************************************************************************************************************\n",
      "ITERATION: The iteration being evaluated.\n",
      "PIPELINE: A summary description of the pipeline being evaluated.\n",
      "SAMPLING %: Percent of the training data to sample.\n",
      "DURATION: Time taken for the current iteration.\n",
      "METRIC: The result of computing score on the fitted pipeline.\n",
      "BEST: The best observed score thus far.\n",
      "********************************************************************************************************************\n",
      "\n",
      " ITERATION   PIPELINE                                       SAMPLING %  DURATION      METRIC      BEST\n",
      "         0   MaxAbsScaler SGD                               100.0000    0:00:34       0.0976    0.0976\n",
      "         1   MaxAbsScaler ExtremeRandomTrees                100.0000    0:00:26       0.0110    0.0976\n",
      "         2   MaxAbsScaler SGD                               100.0000    0:00:20       0.0733    0.0976\n",
      "         3   MaxAbsScaler SGD                               100.0000    0:00:23       0.0543    0.0976\n",
      "         4   MaxAbsScaler RandomForest                      100.0000    0:00:25       0.0086    0.0976\n",
      "         5   MaxAbsScaler RandomForest                      100.0000    0:00:29       0.0117    0.0976\n",
      "         6   MaxAbsScaler SGD                               100.0000    0:00:21       0.0543    0.0976\n",
      "         7   MaxAbsScaler BernoulliNaiveBayes               100.0000    0:00:20       0.0235    0.0976\n",
      "         8   StandardScalerWrapper BernoulliNaiveBayes      100.0000    0:00:19       0.0241    0.0976\n",
      "         9   Ensemble                                       100.0000    0:00:35       0.1089    0.1089\n"
     ]
    }
   ],
   "source": [
    "local_run = experiment.submit(automl_config, show_output = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>automl-local-classification</td><td>AutoML_2e1a8864-811d-45cf-adf6-4a161a165ef6</td><td>automl</td><td>Completed</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/050aedf0-1ce2-495f-a726-be8756f5ab18/resourceGroups/rg_amlsstudentworkspace1/providers/Microsoft.MachineLearningServices/workspaces/amlsstudentworkspace1/experiments/automl-local-classification/runs/AutoML_2e1a8864-811d-45cf-adf6-4a161a165ef6\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: automl-local-classification,\n",
       "Id: AutoML_2e1a8864-811d-45cf-adf6-4a161a165ef6,\n",
       "Type: automl,\n",
       "Status: Completed)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Widget for Monitoring Runs\n",
    "\n",
    "The widget will first report a \"loading\" status while running the first iteration. After completing the first iteration, an auto-updating graph and table will be shown. The widget will refresh once per minute, so you should see the graph update as child runs complete.\n",
    "\n",
    "**Note:** The widget displays a link at the bottom. Use this link to open a web interface to explore the individual run details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e07c331893d424c8f1fa971a7861db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_AutoMLWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', 's…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(local_run).show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Retrieve All Child Runs\n",
    "You can also use SDK methods to fetch all the child runs and see individual metrics that we log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>explained_variance</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.49</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_absolute_error</th>\n",
       "      <td>45.89</td>\n",
       "      <td>46.43</td>\n",
       "      <td>47.35</td>\n",
       "      <td>46.27</td>\n",
       "      <td>62.63</td>\n",
       "      <td>43.64</td>\n",
       "      <td>46.07</td>\n",
       "      <td>45.17</td>\n",
       "      <td>43.64</td>\n",
       "      <td>44.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_absolute_error</th>\n",
       "      <td>41.60</td>\n",
       "      <td>39.25</td>\n",
       "      <td>43.73</td>\n",
       "      <td>40.70</td>\n",
       "      <td>51.00</td>\n",
       "      <td>37.72</td>\n",
       "      <td>39.72</td>\n",
       "      <td>41.39</td>\n",
       "      <td>37.67</td>\n",
       "      <td>39.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normalized_mean_absolute_error</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normalized_median_absolute_error</th>\n",
       "      <td>0.13</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normalized_root_mean_squared_error</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normalized_root_mean_squared_log_error</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_score</th>\n",
       "      <td>0.48</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.47</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>root_mean_squared_error</th>\n",
       "      <td>55.44</td>\n",
       "      <td>56.84</td>\n",
       "      <td>57.18</td>\n",
       "      <td>56.22</td>\n",
       "      <td>79.60</td>\n",
       "      <td>53.31</td>\n",
       "      <td>58.35</td>\n",
       "      <td>54.54</td>\n",
       "      <td>53.30</td>\n",
       "      <td>54.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>root_mean_squared_log_error</th>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spearman_correlation</th>\n",
       "      <td>0.70</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           0     1     2     3     4     5  \\\n",
       "explained_variance                     0.50  0.48  0.48  0.49  -0.03 0.54    \n",
       "mean_absolute_error                    45.89 46.43 47.35 46.27 62.63 43.64   \n",
       "median_absolute_error                  41.60 39.25 43.73 40.70 51.00 37.72   \n",
       "normalized_mean_absolute_error         0.14  0.14  0.15  0.14  0.20  0.14    \n",
       "normalized_median_absolute_error       0.13  0.12  0.14  0.13  0.16  0.12    \n",
       "normalized_root_mean_squared_error     0.17  0.18  0.18  0.18  0.25  0.17    \n",
       "normalized_root_mean_squared_log_error 0.17  0.17  0.17  0.17  0.23  0.16    \n",
       "r2_score                               0.48  0.46  0.45  0.47  -0.06 0.52    \n",
       "root_mean_squared_error                55.44 56.84 57.18 56.22 79.60 53.31   \n",
       "root_mean_squared_log_error            0.43  0.43  0.44  0.44  0.59  0.42    \n",
       "spearman_correlation                   0.70  0.68  0.67  0.68  0.46  0.72    \n",
       "\n",
       "                                           6     7     8     9  \n",
       "explained_variance                     0.45  0.52  0.54  0.53   \n",
       "mean_absolute_error                    46.07 45.17 43.64 44.33  \n",
       "median_absolute_error                  39.72 41.39 37.67 39.80  \n",
       "normalized_mean_absolute_error         0.14  0.14  0.14  0.14   \n",
       "normalized_median_absolute_error       0.12  0.13  0.12  0.12   \n",
       "normalized_root_mean_squared_error     0.18  0.17  0.17  0.17   \n",
       "normalized_root_mean_squared_log_error 0.17  0.16  0.16  0.16   \n",
       "r2_score                               0.43  0.50  0.52  0.51   \n",
       "root_mean_squared_error                58.35 54.54 53.30 54.06  \n",
       "root_mean_squared_log_error            0.44  0.43  0.42  0.42   \n",
       "spearman_correlation                   0.68  0.70  0.72  0.71   "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "children = list(local_run.get_children())\n",
    "metricslist = {}\n",
    "for run in children:\n",
    "    properties = run.get_properties()\n",
    "    metrics = {k: v for k, v in run.get_metrics().items() if isinstance(v, float)}\n",
    "    metricslist[int(properties['iteration'])] = metrics\n",
    "\n",
    "rundata = pd.DataFrame(metricslist).sort_index(1)\n",
    "rundata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the Best Model\n",
    "\n",
    "Below we select the best pipeline from our iterations. The `get_output` method returns the best run and the fitted model. The Model includes the pipeline and any pre-processing.  Overloads on `get_output` allow you to retrieve the best run and fitted model for *any* logged metric or for a particular *iteration*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: automl-local-regression,\n",
      "Id: AutoML_64ef6e81-abdf-47b5-a4a6-acb0cd127f66_8,\n",
      "Type: None,\n",
      "Status: Completed)\n",
      "Pipeline(memory=None,\n",
      "     steps=[('StandardScalerWrapper', <automl.client.core.common.model_wrappers.StandardScalerWrapper object at 0x7fbd8ff38780>), ('LassoLars', LassoLars(alpha=0.001, copy_X=True, eps=2.220446049250313e-16,\n",
      "     fit_intercept=True, fit_path=True, max_iter=500, normalize=False,\n",
      "     positive=False, precompute='auto', verbose=False))])\n"
     ]
    }
   ],
   "source": [
    "best_run, fitted_model = local_run.get_output()\n",
    "print(best_run)\n",
    "print(fitted_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Model Based on Any Other Metric\n",
    "Show the run and the model that has the smallest `root_mean_squared_error` value (which turned out to be the same as the one with largest `spearman_correlation` value):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: automl-local-regression,\n",
      "Id: AutoML_64ef6e81-abdf-47b5-a4a6-acb0cd127f66_8,\n",
      "Type: None,\n",
      "Status: Completed)\n",
      "Pipeline(memory=None,\n",
      "     steps=[('StandardScalerWrapper', <automl.client.core.common.model_wrappers.StandardScalerWrapper object at 0x7fbd8fef6160>), ('LassoLars', LassoLars(alpha=0.001, copy_X=True, eps=2.220446049250313e-16,\n",
      "     fit_intercept=True, fit_path=True, max_iter=500, normalize=False,\n",
      "     positive=False, precompute='auto', verbose=False))])\n"
     ]
    }
   ],
   "source": [
    "lookup_metric = \"root_mean_squared_error\"\n",
    "best_run, fitted_model = local_run.get_output(metric = lookup_metric)\n",
    "print(best_run)\n",
    "print(fitted_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model from a Specific Iteration\n",
    "Show the run and the model from the third iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run(Experiment: automl-local-regression,\n",
      "Id: AutoML_64ef6e81-abdf-47b5-a4a6-acb0cd127f66_3,\n",
      "Type: None,\n",
      "Status: Completed)\n",
      "Pipeline(memory=None,\n",
      "     steps=[('StandardScalerWrapper', <automl.client.core.common.model_wrappers.StandardScalerWrapper object at 0x7fbd8fe8e0b8>), ('LightGBMRegressor', <automl.client.core.common.model_wrappers.LightGBMRegressor object at 0x7fbd8fecd160>)])\n"
     ]
    }
   ],
   "source": [
    "iteration = 3\n",
    "third_run, third_model = local_run.get_output(iteration = iteration)\n",
    "print(third_run)\n",
    "print(third_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict on training and test set, and calculate model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate accuracy on the prediction\n",
    "acc = np.average(y_predtest == y_test)\n",
    "print('Accuracy is', acc)"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "savitam"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
